{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "apps_list = [\"Impulse - Brain Training\",\n",
    "\"Planet Fitness Workouts\",\n",
    "\"MyFitness Pal Calorie Counter\",\n",
    "\"Yuka Food Cosmetic Scanner\",\n",
    "\"ShutEye Sleep Tracker Sound\",\n",
    "\"Me Daily Routine Planner\",\n",
    "\"BetterMe Health Coaching\",\n",
    "\"JustFit Lazy Workout Fit\",\n",
    "\"Sweatcoin Walking Step Counter\",\n",
    "\"All Trails Hike Bike Run\",\n",
    "\"myCigna\",\n",
    "\"I am Daily Affirmations\",\n",
    "\"BetterSleep Relax and Sleep\",\n",
    "\"Finch Self Care Pet\",\n",
    "\"Motivation Daily quotes\",\n",
    "\"Calm\",\n",
    "\"Strava\",\n",
    "\"Nike Run Club\",\n",
    "\"Mindbody Fitness Salon Spa\",\n",
    "\"Peak\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_sent_dict = {\"has_leaderboard\" : 0, \"has_challenges\": 0, \"has_points\": 0, \"has_badges\": 0, \"has_feedback\": 0, \"has_social\": 0, \"has_tracking\": 0,\\\n",
    "                \"has_goals\": 0, \"has_narrative\": 0, \"has_collab\": 0}\n",
    "neg_sent_dict = {\"has_leaderboard\" : 0, \"has_challenges\": 0, \"has_points\": 0, \"has_badges\": 0, \"has_feedback\": 0, \"has_social\": 0, \"has_tracking\": 0,\\\n",
    "                \"has_goals\": 0, \"has_narrative\": 0, \"has_collab\": 0}\n",
    "avg_pos_count_dict = {\"has_leaderboard\" : 0, \"has_challenges\": 0, \"has_points\": 0, \"has_badges\": 0, \"has_feedback\": 0, \"has_social\": 0, \"has_tracking\": 0,\\\n",
    "                \"has_goals\": 0, \"has_narrative\": 0, \"has_collab\": 0}\n",
    "neg_count_dict = {\"has_leaderboard\" : 0, \"has_challenges\": 0, \"has_points\": 0, \"has_badges\": 0, \"has_feedback\": 0, \"has_social\": 0, \"has_tracking\": 0,\\\n",
    "                \"has_goals\": 0, \"has_narrative\": 0, \"has_collab\": 0}\n",
    "mentions_dict = {\"has_leaderboard\" : 0, \"has_challenges\": 0, \"has_points\": 0, \"has_badges\": 0, \"has_feedback\": 0, \"has_social\": 0, \"has_tracking\": 0,\\\n",
    "                \"has_goals\": 0, \"has_narrative\": 0, \"has_collab\": 0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the total times positive sentiment attached to a rating was found in a mechanism was {'has_leaderboard': 6, 'has_challenges': 16, 'has_points': 18, 'has_badges': 7, 'has_feedback': 20, 'has_social': 20, 'has_tracking': 20, 'has_goals': 19, 'has_narrative': 20, 'has_collab': 5}\n",
      "pos sent pre avg\n",
      "{'has_leaderboard': 4.715536088235294, 'has_challenges': 13.775681073889894, 'has_points': 13.987016313139156, 'has_badges': 5.72629125, 'has_feedback': 15.87434577711026, 'has_social': 15.802885559977785, 'has_tracking': 15.980874656621154, 'has_goals': 16.422050532317083, 'has_narrative': 15.104546946393729, 'has_collab': 4.85845}\n",
      "post avg {'has_narrative': 0.7552273473196864, 'has_points': 0.7770564618410642, 'has_leaderboard': 0.785922681372549, 'has_social': 0.7901442779988892, 'has_feedback': 0.7937172888555131, 'has_tracking': 0.7990437328310577, 'has_badges': 0.8180416071428571, 'has_challenges': 0.8609800671181184, 'has_goals': 0.8643184490693202, 'has_collab': 0.97169}\n",
      "the total times neg sentiment attached to a rating was found in a mechanism was {'has_leaderboard': 2, 'has_challenges': 9, 'has_points': 9, 'has_badges': 2, 'has_feedback': 17, 'has_social': 16, 'has_tracking': 14, 'has_goals': 15, 'has_narrative': 17, 'has_collab': 2}\n",
      "neg sent\n",
      "{'has_leaderboard': -1.07049, 'has_challenges': -4.777490634920635, 'has_points': -4.9631425, 'has_badges': -1.2572999999999999, 'has_feedback': -9.572427083333332, 'has_social': -8.881725777777778, 'has_tracking': -8.676005082251082, 'has_goals': -8.539861666666667, 'has_narrative': -10.629807790584413, 'has_collab': -1.2857}\n",
      "post avg {'has_collab': -0.64285, 'has_badges': -0.6286499999999999, 'has_narrative': -0.6252828112108478, 'has_tracking': -0.6197146487322202, 'has_goals': -0.5693241111111111, 'has_feedback': -0.5630839460784314, 'has_social': -0.5551078611111111, 'has_points': -0.5514602777777777, 'has_leaderboard': -0.535245, 'has_challenges': -0.5308322927689595}\n",
      "mentions\n",
      "{'has_leaderboard': 98, 'has_challenges': 428, 'has_points': 274, 'has_badges': 44, 'has_feedback': 368, 'has_social': 684, 'has_tracking': 1649, 'has_goals': 1037, 'has_narrative': 737, 'has_collab': 9}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "folder_path = os.getcwd()\n",
    "\n",
    "subdir_name = 'data_analysis'\n",
    "index = 0\n",
    "new_subdirectory_path = os.path.join(folder_path, subdir_name)\n",
    "total_lb = 0\n",
    "total_challenges = 0\n",
    "total_points = 0\n",
    "total_badges = 0\n",
    "total_fb = 0\n",
    "total_social = 0\n",
    "total_tracking = 0\n",
    "total_goal = 0\n",
    "total_nar = 0\n",
    "total_collab = 0\n",
    "\n",
    "if not os.path.exists(new_subdirectory_path):\n",
    "    # Create the new subdirectory\n",
    "        os.makedirs(new_subdirectory_path)\n",
    "        print(f\"Subdirectory '{subdir_name}' created successfully.\")\n",
    "count = 0\n",
    "\n",
    "for app_name in apps_list:\n",
    "    vader_csv = app_name + \"_vader_data.csv\"\n",
    "    csv_file_path = os.path.join(new_subdirectory_path, vader_csv)\n",
    "    mechanisms = [\"has_leaderboard\", \"has_challenges\", \"has_points\", \"has_badges\", \"has_feedback\", \"has_social\", \"has_tracking\",\\\n",
    "                \"has_goals\", \"has_narrative\", \"has_collab\"]\n",
    "    df = pd.read_csv(csv_file_path)\n",
    "    df.head()\n",
    "    #print(app_name)\n",
    "    # print(df.columns)\n",
    "    \n",
    "    for x in mechanisms:\n",
    "       \n",
    "        #sent_val = df.loc[((df['rating']) == 4) & ((df['Element type'])==x) & (((df['vader_sentiment'])=='pos')), 'vader_sentiment_score'].values\n",
    "        pos_val = df.loc[((df['Element type'])==x) & (((df['vader_sentiment'])=='pos')), 'vader_sentiment_score'].values #get the sent score correspinding w pos and elemn type \n",
    "        if pos_val.size != 0 :\n",
    "             pos_sent_dict[x] = pos_sent_dict[x] + pos_val.mean() \n",
    "             avg_pos_count_dict[x] = avg_pos_count_dict[x] + 1 #count how many overall pos total (max 5 bec 5 ratings)\n",
    "        neg_val = df.loc[((df['Element type'])==x) & (((df['vader_sentiment'])=='neg')), 'vader_sentiment_score'].values #get the sent score correspinding w pos and elemn type \n",
    "        if neg_val.size != 0 :\n",
    "             neg_sent_dict[x] = neg_sent_dict[x] + neg_val.mean() \n",
    "             neg_count_dict[x] = neg_count_dict[x] + 1\n",
    "        \n",
    "        val = df.loc[((df['Element type'])==x), 'Mentions'].values\n",
    "        #get the number of mentions for that mechanism\n",
    "        if val.size != 0:\n",
    "            sum = val[0]\n",
    "            mentions_dict[x] = mentions_dict[x] + sum\n",
    "\n",
    "print(\"the total times positive sentiment attached to a rating was found in a mechanism was\", avg_pos_count_dict)\n",
    "print(\"pos sent pre avg\")\n",
    "pos_sorted_dict = {}\n",
    "print(pos_sent_dict) \n",
    "for key in pos_sent_dict.keys():\n",
    "     total = pos_sent_dict[key]\n",
    "     total = total/avg_pos_count_dict[key]\n",
    "     pos_sorted_dict[key] = total\n",
    "\n",
    "pos_sorted_dict = dict(sorted(pos_sorted_dict.items(), key=lambda item: item[1]))\n",
    "print(\"post avg\", pos_sorted_dict)\n",
    "\n",
    "neg_sorted_dict = {}\n",
    "print(\"the total times neg sentiment attached to a rating was found in a mechanism was\", neg_count_dict)\n",
    "print(\"neg sent\")\n",
    "print(neg_sent_dict)\n",
    "for key in neg_sent_dict.keys():\n",
    "     total = neg_sent_dict[key]\n",
    "     total = total/neg_count_dict[key]\n",
    "     neg_sorted_dict[key] = total\n",
    "\n",
    "\n",
    "neg_sorted_dict = dict(sorted(neg_sorted_dict.items(), key=lambda item: item[1]))\n",
    "print(\"post avg\", neg_sorted_dict)\n",
    "\n",
    "print(\"mentions\")\n",
    "print(mentions_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'has_leaderboard': 4.715536088235294, 'has_challenges': 13.775681073889894, 'has_points': 13.987016313139156, 'has_badges': 5.72629125, 'has_feedback': 15.87434577711026, 'has_social': 15.802885559977785, 'has_tracking': 15.980874656621154, 'has_goals': 16.422050532317083, 'has_narrative': 15.104546946393729, 'has_collab': 4.85845}\n"
     ]
    }
   ],
   "source": [
    "print(pos_sent_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data written to output.csv\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "# Assuming you have dictionaries named dict1, dict2, dict3, etc.\n",
    "\n",
    "\n",
    "# Create a list of dictionaries\n",
    "list_of_dicts = [avg_pos_count_dict, pos_sent_dict, pos_sorted_dict, neg_count_dict, neg_sent_dict, neg_sorted_dict, mentions_dict]\n",
    "names = [\"avg_pos_count_dict\", \"pos_sent_dict\", \"pos_sorted_dict\", \"neg_count_dict\",\"neg_sent_dict\", \"neg_count_dict\", \"mentions_dict\"]\n",
    "\n",
    "# Extract common keys\n",
    "common_keys = set(key for dictionary in list_of_dicts for key in dictionary)\n",
    "\n",
    "# Specify the CSV file path\n",
    "csv_file_path = 'output.csv'\n",
    "\n",
    "# Write to CSV file\n",
    "with open(csv_file_path, 'w', newline='') as csvfile:\n",
    "    fieldnames = ['Dictionary'] + list(common_keys)\n",
    "    writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "\n",
    "    # Write header\n",
    "    writer.writeheader()\n",
    "\n",
    "    # Write data\n",
    "    count = 0\n",
    "    for i, dictionary in enumerate(list_of_dicts, start=1):\n",
    "        row = {'Dictionary': f'dict{names[count]}'}\n",
    "        count = count +1\n",
    "        row.update(dictionary)\n",
    "        writer.writerow(row)\n",
    "\n",
    "print(f'Data written to {csv_file_path}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'has_leaderboard': 18, 'has_challenges': 43, 'has_points': 42, 'has_badges': 2, 'has_feedback': 63, 'has_social': 122, 'has_tracking': 282, 'has_goals': 53, 'has_narrative': 115, 'has_collab': 3}\n",
      "{'has_leaderboard': 80, 'has_challenges': 385, 'has_points': 232, 'has_badges': 42, 'has_feedback': 303, 'has_social': 557, 'has_tracking': 1361, 'has_goals': 983, 'has_narrative': 618, 'has_collab': 6}\n"
     ]
    }
   ],
   "source": [
    "lb_count = 0 \n",
    "\n",
    "pos_count_dict = {\"has_leaderboard\" : 0, \"has_challenges\": 0, \"has_points\": 0, \"has_badges\": 0, \"has_feedback\": 0, \"has_social\": 0, \"has_tracking\": 0,\\\n",
    "                \"has_goals\": 0, \"has_narrative\": 0, \"has_collab\": 0}\n",
    "neg_count_dict = {\"has_leaderboard\" : 0, \"has_challenges\": 0, \"has_points\": 0, \"has_badges\": 0, \"has_feedback\": 0, \"has_social\": 0, \"has_tracking\": 0,\\\n",
    "                \"has_goals\": 0, \"has_narrative\": 0, \"has_collab\": 0}\n",
    "\n",
    "for app_name in apps_list:\n",
    "    vader_csv = app_name + \"_vader_data.csv\"\n",
    "    csv_file_path = os.path.join(new_subdirectory_path, vader_csv)\n",
    "    \n",
    "    mechanisms = [\"has_leaderboard\", \"has_challenges\", \"has_points\", \"has_badges\", \"has_feedback\", \"has_social\", \"has_tracking\",\\\n",
    "                \"has_goals\", \"has_narrative\", \"has_collab\"]\n",
    "    df = pd.read_csv(csv_file_path)\n",
    "    df.head()\n",
    "    for x in mechanisms:\n",
    "        cnt = df.loc[((df['Element type'])==x) & (((df['vader_sentiment'])=='neg')), 'count'].values #get the sent score correspinding w pos and elemn type \n",
    "        if cnt.size != 0:\n",
    "            neg_count_dict[x] = cnt.sum() + neg_count_dict[x] \n",
    "        cnt = df.loc[((df['Element type'])==x) & (((df['vader_sentiment'])=='pos')), 'count'].values #get the sent score correspinding w pos and elemn type \n",
    "        if cnt.size != 0:\n",
    "            pos_count_dict[x] = cnt.sum() + pos_count_dict[x] \n",
    "print (neg_count_dict)\n",
    "print(pos_count_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "where value is (neg count, pos count)\n",
      "{'has_leaderboard': [18, 80], 'has_challenges': [43, 385], 'has_points': [42, 232], 'has_badges': [2, 42], 'has_feedback': [63, 303], 'has_social': [122, 557], 'has_tracking': [282, 1361], 'has_goals': [53, 983], 'has_narrative': [115, 618], 'has_collab': [3, 6]}\n"
     ]
    }
   ],
   "source": [
    "total_reviews = 1500*20\n",
    "percent_keys = {}\n",
    "for key in pos_sent_dict.keys():\n",
    "    percent = pos_sent_dict[key]/total_reviews\n",
    "    percent = percent*10\n",
    "    percent_keys[key] = [neg_count_dict[key], pos_count_dict[key]]\n",
    "   # print(key, \"can be found in\" ,percent, \"%\", \" reviews\")\n",
    "print (\"where value is (neg count, pos count)\")\n",
    "print(percent_keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data written to output.csv\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "# Assuming you have dictionaries named dict1, dict2, dict3, etc.\n",
    "\n",
    "\n",
    "# Create a list of dictionaries\n",
    "list_of_dicts = [percent_keys]\n",
    "names = [\"Total Number (neg, pos)\"]\n",
    "\n",
    "# Extract common keys\n",
    "common_keys = set(key for dictionary in list_of_dicts for key in dictionary)\n",
    "\n",
    "# Specify the CSV file path\n",
    "csv_file_path = 'output.csv'\n",
    "\n",
    "# Write to CSV file\n",
    "with open(csv_file_path, mode='a', newline='') as csvfile:\n",
    "    fieldnames = ['Dictionary'] + list(common_keys)\n",
    "    writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "\n",
    "    # Write header\n",
    "    writer.writeheader()\n",
    "\n",
    "    # Write data\n",
    "    count = 0\n",
    "    for i, dictionary in enumerate(list_of_dicts, start=1):\n",
    "        row = {'Dictionary': f'dict{names[count]}'}\n",
    "        count = count +1\n",
    "        row.update(dictionary)\n",
    "        writer.writerow(row)\n",
    "\n",
    "print(f'Data written to {csv_file_path}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "virtualenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
